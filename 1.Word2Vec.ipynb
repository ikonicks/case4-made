{"cells":[{"cell_type":"markdown","metadata":{"id":"PuM9XvCC23uF"},"source":["# Практическая работа 4 по ТОВИИ\n","# Векторные представления слов\n"]},{"cell_type":"markdown","metadata":{"id":"G1FhgOr04D32"},"source":["# О посимвольном представлении текста\n","Несомненно, текст записывается как последовательность символов. Но человек обычно не обрабатывает каждый символ отдельно, а воспринимает \"слова\" целиком.\n","\n","Сможете ли вы прочитать этот [текст](https://habr.com/ru/articles/148896/) ?\n","\n"," **По рзелульаттам илссеовадний одонго анлигйсокго унвиертисета, не иеемт занчнеия, в кокам пряокде рсапожолены бкувы в солве. Галвоне, чотбы преавя и пслоендяя бквуы блыи на мсете. Осатьлыне бкувы мгоут селдовтаь в плоонм бсепордяке, все-рвано ткест чтаитсея без побрелм. Пичрионй эгото ялвятеся то, что мы чиатем не кдаужю бкуву по отдльенотси, а все солво цликеом.**\n","\n","В английском варианте это звучало так:\n","\n","**Arocdnicg to rsceearch at Cmabrigde Uinervtisy, it deosn’t mttaer in waht oredr the ltteers in a wrod are, the olny iprmoatnt tihng is taht the frist and lsat ltteer are in the rghit pcale. The rset can be a toatl mses and you can sitll raed it wouthit pobelrm. Tihs is buseace the huamn mnid deos not raed ervey lteter by istlef, but the wrod as a wlohe.**\n","\n","Таким образом, текст выгодней представлять не как последовательность символов, а как последовательность слов.\n"]},{"cell_type":"markdown","metadata":{"id":"psYi8z3h23uT"},"source":["# Унитарное кодирование\n","Пожалуй самым простым векторным представлением является *унитарное кодирование* (по-английски one-hot encoding).\n","\n","Возьмем какой-либо текст, разобьем его на слова-элементы и составим словарь таких слов, в котором каждому слову будет приписан его номер в словаре.\n","\n","Этот номер слова можно представить в бинарном виде, сопоставим каждому слову в словаре *бинарный вектор*, состоящий из нулей и только одной единицы. Положение единицы в векторе показывает номер слова.\n","\n","![img](https://drive.google.com/uc?id=1hDY2EKB7ND-Uxq9FnKVtxC-U-0bnuiTe)\n","\n","В векторе будет столько элементов, сколько слов в словаре мы записали.\n","\n","Обратите внимание, что единичка, по сути, является признаком слова: стоит единичка в пятом элементе, значит слово номер пять.\n","\n","Вообще, в словарь мы можем добавлять какие угодно \"слова\", это могут быть обычные привычные нам слова, части слов и даже отдельные буквы, словосочетания и целые предложения, знаки препинания, смайлики, и прочее. Главное, что у всех этих \"слов\" есть номер, представленный унитарным вектором.\n","\n","Текст является последовательностью слов, а в унитарном представлении - последовательностью унитарных векторов.\n","\n","![img](https://drive.google.com/uc?id=1uEodrFkeG433O_zCWf3EpR8JVPYEFysx)\n","\n","Унитарное кодирование используется и для других типов информации, для изображений, сигналов и пр. Хорошим свойством является то, что унитарное представление не зависит от длины слова, ведь в словарь мы можем добавлять слова разной длины, хоть из одной буквы, хоть целое словосочетание.\n","\n","Однако такое представление не дает нам никаких новых интересных свойств, ведь унитарные вектора никак не связаны между собой и зависят от нашего произвола - в каком порядке слова в словарь добавляем, такой вектор и получим.\n","\n","Поэтому создают другие, более интересные, векторные представления."]},{"cell_type":"markdown","metadata":{"id":"x_7KaRdJ23uT"},"source":["# Word2vec\n","Хочется как-то связать между собой слова и их векторные представления, ведь в реальных текстах слова, конечно же, связаны между собой **смыслом**. Вряд ли кто-то захочет читать тексты из случайных слов.\n","\n","Если есть взаимосвязь между словами текста, то ее можно уловить, вычислить.\n","\n","А давайте попробуем сделать так:\n","- возьмем из текста три слова подряд.\n","- закроем одно слово и попробуем его угадать по двум оставшимся.\n","\n","Во многих случаях, но конечно не всегда, это нам удастся. Попробуйте угадать какое слово скрыто под звездочками во фразе \"Мама мыла ....\".\n","Если вы сказали \"раму\", то угадали, но могли сказать \"пол\" и не угадали.\n","\n","Давайте возьмем больше слов \"Мама мыла оконную ...\": тут легче угадать слово \"раму\", но все равно есть и другие варианты (придумайте).\n","\n","И все же, для многих последовательностей слов можно угадать какое слово закрыто, так пусть этим займется компьютер.\n","\n","Текст это последовательность слов, слова можно представить унитарными векторами. Нам надо лишь по нескольким унитарным векторам вычислять следующий. Это абсолютно то же самое, как если бы мы хотели обучить нейронную сеть. Известны входы - несколько унитарных векторов, знаем выход - один унитарный вектор, давайте обучим.\n","\n","Можно посмотреть и с другой стороны, если по нескольким словам мы угадываем следующее, то давайте наоборот, по слову угадаем какие слова ему предшествовали. Технически задача такая же. Знаем вход - один унитарный вектор, знаем выход - несколько унитарных векторов - так давайте обучим нейронную сеть.\n","\n","Эти подходы можно совместить, по нескольким векторам угадываем один пропущенный, а затем по нему угадываем обратно какие вектора были изначально, или, другими словами, угадываем слово по словам его окружающим, а затем по этому слову угадываем окружающие слова. Обычно угадывают среднее слово из трех, но это вовсе не обязательно.\n","\n","Такая технология получила название **word2vec** (произносится \"ворд ту век\"). На картинке показана для пяти слов, обозначенных буквой V с индексом в скобках.  Первую половинку - угадывание слова по окружению - назвали CBOW, вторую - угадывания окружения по слову - SkipGram.\n","\n","![img](https://drive.google.com/uc?id=18pa20uv6xi8tGC6pdOS3Vc11KUUcpW2e)"]},{"cell_type":"markdown","source":["CBOW предсказывает текущее слово на основе контекста вокруг него. Например, для фразы «синее небо над головой» модель CBOW будет пытаться предсказать слово «небо» на основе контекстных слов «синее», «над», «головой». CBOW быстро обрабатывает большие объёмы данных, но менее эффективен для редких слов.\n","\n","Skip-Gram, в отличие от CBOW, предсказывает контекстные слова для данного целевого слова. Для того же примера модель Skip-Gram будет пытаться предсказать слова «синее», «над», «головой» на основе слова «небо». Skip-Gram медленнее обрабатывает данные, но лучше работает с редкими словами и менее частыми контекстами."],"metadata":{"id":"58ep7Xw56fUi"}},{"cell_type":"markdown","metadata":{"id":"yeHc1Oxn23uU"},"source":["Посмотрим на CBOW (это сокращение от Continuous Bag of Word, непрерывный мешок слов).\n","\n","Мы можем использовать простую нейронную сеть только с одним скрытым слоем для него.\n","\n","Унитарные вектора слов-окружения переводятся в скрытом слое в некоторые выходы, а затем по выходам этого скрытого слоя считается унитарный вектор исходного слова.\n","\n","Перевод унитарного представления слов-окружения в скрытом слое производится, как мы понимаем из работы нейронной сети, умножением на матрицу весов W. Ее размер (число нейронов в скрытом слое) * (число слов в словаре). Нет необходимости делать эту матрицу разной для разных слов-окружений, пусть будет одна.\n","\n","Аналогично, переход из скрытого слоя на выход также делается с помощью умножения на матрицу W'. Ее размер (число слов в словаре) * (число нейронов в скрытом слое).\n","\n","Матрица W' нам не важна, но посмотрим более внимательно на матрицу W.\n","\n","Она умножается на унитарный вектор, т.е. вектор, в котором все элементы нули кроме одного. Что произойдет при таком умножении?\n","\n","Правильно, выберется только один столбец из матрицы, с таким номером, на какой позиции стоит единичка во входом векторе. Но положение этой единички означает номер слова в словаре! Значит, каждому слову из словаря соответствует свой вектор-столбец в матрице W. Его размерность определяется числом нейронов в скрытом слое, которое мы задаем сами при обучении. **Эти вектора-столбцы и являются новым векторным представлением слов**.   \n","\n","Итак, вкратце, еще раз.\n","- Берем тексты\n","- разбиваем их на последовательность слов\n","- переводим слова в унитарные вектора\n","- на парах (соседние слова)-(среднее слово) обучаем простую нейронную сеть CBOW с ее матрицей W.\n","- используем столбцы матрицы W как новое векторное представление слов. Длина этих векторов задается произвольно при обучении.\n","\n","![img](https://drive.google.com/uc?id=1bTpfqH0niwJKwMRHKdNbuOFiR9jucCZe)\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hqo4y3v523uV"},"source":["# Геометрия слов\n","Создав векторные представления для слов, можно их использовать в различных *геометрических* операциях: сложить вектора, вычесть, найти угол меду ними.\n","\n","И, что наиболее удивительно в таких векторных представлениях, эти геометрические операции с векторами имеют **смысл** с точки зрения самих слов.\n","\n","Например:\n","* Король - мужчина + женщина = Королева\n","* Великобритания - Лондон + Москва = Россия\n"," и др.\n","\n"," Прежде чем смотреть на примеры, несколько слов о сравнении векторов.\n","\n","## Косинусное расстояние.\n","\n","Вектора можно сравнивать между собой, логично, что близкие вектора означают близкие по смыслу слова. Но как именно сравнивать вектора?\n","\n","Оказалось, что простое Евклидово расстояние между векторами не так интересно, более интересно сравнивать угол между векторами или, правильнее, косинус угла.\n","\n","Ну-ка, вспоминайте геометрию, как посчитать косинус угла между векторами?\n","\n","А вот так: скалярное произведение векторов поделить на длины этих векторов.\n","\n","![img](https://drive.google.com/uc?id=1vxVWdSAjY5oK6U7CtGadB0-2T5YLFmSh)\n","\n","Часто векторные представления *нормализуют*, т.е. приводят к единичной длине, тогда ее и считать не надо.\n","\n","Итак, мера схожести векторов - косинус угла между ними. Близкие по смыслу слова скорей всего дадут близкие по углу вектора."]},{"cell_type":"markdown","metadata":{"id":"_BOipolf23uW"},"source":["# Библиотека gensim\n","\n","А теперь примеры. Поиграть с векторами онлайн вы можете [здесь](https://rare-technologies.com/word2vec-tutorial/#app), но давайте и сами реализуем.  \n","\n","Нам поможет библиотека [gensim](https://radimrehurek.com/gensim/index.html). Установим ее.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXyn2JWv23uW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745416672462,"user_tz":-180,"elapsed":17883,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"721eb5d0-801b-44a4-9e0a-38ec64c55f47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Collecting numpy<2.0,>=1.18.5 (from gensim)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.14.1\n","    Uninstalling scipy-1.14.1:\n","      Successfully uninstalled scipy-1.14.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"]}],"source":["!pip install gensim"]},{"cell_type":"markdown","metadata":{"id":"P0J6XlEf23uY"},"source":["Подключим вспомогательную библиотеку для записи действий."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtqCCWh423uY"},"outputs":[],"source":["import logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"k2HHRtF923uZ"},"source":["Скачаем уже обученную модель [word2vec](https://radimrehurek.com/gensim/models/word2vec.html), она была обучена на огромном наборе текстов на английском языке из 3 млн. слов и занимает около 2 Гигабайт, придется подождать. Это надо сделать только один раз. Модель загружается в виде специального объекта, в котором прописаны многие методы для работы с векторами.\n","\n","*Для учителя: иногда сайт обрывает связь и закачку, рекомендуется заранее скачать массивы используя методы load(), save(), или используйте меньшие вектора, или скачайте заранее и поместите в директорию /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zw26YKfY23ua"},"outputs":[],"source":["# import gensim.downloader as api\n","# wv = api.load('word2vec-google-news-300') # большая модель"]},{"cell_type":"markdown","metadata":{"id":"ptoeU-ro-YHI"},"source":["Воспользуемся корпусом поменьше и обучим на нем модель word2vec."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_q5qYCi3txa"},"outputs":[],"source":["# Корпус поменьше\n","import numpy as np\n","import gensim.downloader as api\n","from gensim.models.word2vec import Word2Vec\n","corpus = api.load('text8') # загружаем корпус текстов\n","model = Word2Vec(corpus) # обучаем модель ~ 5 минут\n","wv=model.wv"]},{"cell_type":"markdown","source":["Корпус text8 — это предобработанный текстовый набор данных, который состоит из одного длинного файла с токенизированными словами (в нижнем регистре, без пунктуации и цифр).\n","\n","Формат: последовательность слов (токенов) без разделения на предложения или абзацы.\n","\n","Пример содержимого: \"cat set on ...\" (сплошной поток слов).\n","\n","Предобработка: удалены все не буквенные символы, слова приведены к lowercase.\n","\n","Модель Word2Vec сама разбивает этот поток на \"предложения\" (по умолчанию окном в 5 слов) при обучении."],"metadata":{"id":"Zlu7pBV3lVR2"}},{"cell_type":"markdown","metadata":{"id":"prcvk_j023ua"},"source":["Выведем на экран первые 10 слов из словаря, которые хранятся в поле .index_to_key\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1745422404484,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"QeBsRaP_23ub","outputId":"35bc28af-688b-4ab9-e663-78845a0e2c16"},"outputs":[{"output_type":"stream","name":"stdout","text":["word #0/71290 is the\n","word #1/71290 is of\n","word #2/71290 is and\n","word #3/71290 is one\n","word #4/71290 is in\n","word #5/71290 is a\n","word #6/71290 is to\n","word #7/71290 is zero\n","word #8/71290 is nine\n","word #9/71290 is two\n"]}],"source":["for index, word in enumerate(wv.index_to_key):\n","    if index == 10:\n","        break\n","    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"]},{"cell_type":"markdown","metadata":{"id":"oqjsNfe223ub"},"source":["Получить вектор слова можно используя это слово как индекс. Получим для слова 'king'. Это вектор из 100 элементов. Конечно, это слово должно быть в словаре и именно в таком виде, иначе возникнет ошибка. Важен и регистр букв, попробуйте слово 'kinG'."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1745422408434,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"Y7rmj06m23uc","outputId":"3fe31065-0afb-4153-fccd-7a6bf9ef76a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.45911887  0.05671151  1.6638522   1.597603    1.4071803  -0.09621739\n","  0.47989964  0.14477304 -0.3538567   2.5724034  -0.9408368  -2.303506\n"," -0.56143934  3.184799   -1.8800224   0.07425999 -2.0183694   1.8414277\n","  2.1791997  -2.5500531   2.0957682   1.0371059  -2.8690052  -0.54995227\n","  0.25807092  2.6919146   2.3696513   0.839747    0.5547681  -0.6530799\n"," -0.5011661   1.3547319  -1.4762561   1.1074065   1.6943085   1.486954\n","  2.5215828  -0.98892206 -0.75401914 -1.4959172   0.76310664  1.2531209\n"," -0.37910748  0.98095024 -0.7975154  -2.0084393  -1.4709593  -1.0297674\n","  1.0077916  -2.419613    1.6555521   0.35967442 -1.564899    2.5267413\n"," -0.22482339 -2.0451546  -0.689958   -0.23654532  2.3596456  -1.4153544\n","  2.1341684   0.6942026   1.8306153  -0.6962548   0.54518664 -1.7727566\n"," -2.280922    1.4686406   0.35755005 -4.4781146   0.82279444 -1.316062\n"," -2.4972062  -2.129835    0.1542152  -1.8454729   1.3335834   2.5215187\n"," -2.2730172   2.2656891  -2.518379   -2.5362678  -1.3209723   0.21078417\n","  0.2300512   0.7767485   2.0571344   1.9612482  -1.2563349  -0.32283553\n","  0.843079    0.4086753  -0.38566437 -2.5185387   1.6083583  -0.1473317\n","  3.5085552   1.3425573  -2.7105544  -2.6102397 ]\n"]},{"output_type":"execute_result","data":{"text/plain":["(100,)"]},"metadata":{},"execution_count":25}],"source":["vec_king = wv['king'] # такое слово есть в словаре\n","print(vec_king)\n","vec_king.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"error","timestamp":1745422412369,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"V3CduHpM_u80","colab":{"base_uri":"https://localhost:8080/","height":298},"outputId":"83d4902b-cb22-48e0-ec0b-e99928333050"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"Key 'King' not present\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-ea888bab6efc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvec_king\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'King'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# такого слова нет в словаре\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"Key 'King' not present\""]}],"source":["vec_king = wv['King'] # такого слова нет в словаре"]},{"cell_type":"markdown","metadata":{"id":"Uzk2QWmI23uc"},"source":["Посчитать \"похожесть\" слов, т.е. их векторов, можно с помощью метода `.similarity()`. Чем больше число, тем более похожи слова."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1745422415204,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"YvdK5kQR23uc","outputId":"2eb109ce-d6ed-4b4f-a7d8-8725fd3bb180"},"outputs":[{"output_type":"stream","name":"stdout","text":["'car'\t'minivan'\t0.34\n","'car'\t'bicycle'\t0.59\n","'car'\t'airplane'\t0.55\n","'car'\t'cereal'\t0.18\n","'car'\t'communism'\t-0.15\n"]}],"source":["pairs = [                 # пары слов\n","    ('car', 'minivan'),   # минивэн это тип автомобиля\n","    ('car', 'bicycle'),   # мотоцикл имеет колеса как и автомобиль\n","    ('car', 'airplane'),  # ладно, самолет не колесное средство, но все же средство передвижения\n","    ('car', 'cereal'),    # зерно и автомобиль, хм..\n","    ('car', 'communism'), # какая связь между автомобилем и коммунизмом???\n","]\n","for w1, w2 in pairs:\n","    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"]},{"cell_type":"code","source":["print(wv.similarity('boy', 'girl'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQKW_iTo_7l8","executionInfo":{"status":"ok","timestamp":1745422418004,"user_tz":-180,"elapsed":5,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"f9fe9181-1b7a-4c2b-c2b6-dc609de61369"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.73190594\n"]}]},{"cell_type":"code","source":["print(wv.similarity('boy', 'man'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65wsIZktAO8N","executionInfo":{"status":"ok","timestamp":1745422419786,"user_tz":-180,"elapsed":5,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"519ed815-2f3d-4776-99dd-bed8ba44859e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.532845\n"]}]},{"cell_type":"code","source":["print(wv.similarity('man', 'woman'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBEpKfUtASyj","executionInfo":{"status":"ok","timestamp":1745422421290,"user_tz":-180,"elapsed":6,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"b1c6f7b6-0eaf-4e4c-b561-888c61e48aa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7407474\n"]}]},{"cell_type":"markdown","source":["Забавно)\n","\n","Думаю, так получается, потому что модель сделала акцент больше на \"возрасте\" слов, чем на \"однотипности\" слов. Собственно, значит в обучающем наборе данных, в большинстве случаев, логичнее было делать замену 'boy' <-> 'girl' (с учетом контекста)."],"metadata":{"id":"xMbJ6knfAX8M"}},{"cell_type":"markdown","metadata":{"id":"huAtz1iv23ud"},"source":["Перебирать вручную все пары слов, чтобы найти самые похожие будет трудно, пусть компьютер сравнит все-все вектора и выведет самые похожие на заданный.\n","\n","Метод `.most_similar()` принимает набор слов для которых искать похожие (аргумент positive) и число похожих слов (аргумент topn)\n","\n","(Первый запуск может быть долгим, так как надо посчитать длины всех векторов, потом будет гораздо быстрее)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1745422449528,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"29vJFCWf23ud","outputId":"aa4b2dbe-5750-46de-ef9f-77cd90233220"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('girl', 0.7798120975494385), ('child', 0.7065568566322327), ('person', 0.6697066426277161), ('creature', 0.6514785289764404), ('lover', 0.649685263633728)]\n","[('hamster', 0.7054501175880432), ('bird', 0.6842487454414368), ('breed', 0.6825723052024841), ('goat', 0.6789342761039734), ('kangaroo', 0.6481212377548218)]\n"]}],"source":["print(wv.most_similar(positive=['man', 'woman'], topn=5))\n","print(wv.most_similar(positive=['cat','dog'],negative=['duck'], topn=5))"]},{"cell_type":"markdown","metadata":{"id":"Av4fcfol23ue"},"source":["Найти слово, которое непохоже на остальные? Легко, метод .doesnt_match(). Все слова (их вектора) будут сравнены между собой и выведется то, которое похоже меньше всех."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1745422455069,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"vYnqSCA823ue","outputId":"5a270818-f6f8-4562-9b67-712c1857d0e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["car\n"]}],"source":["print(wv.doesnt_match(('fire', 'water', 'land', 'sea', 'air', 'car')))"]},{"cell_type":"code","source":["print(wv.doesnt_match(('honest', 'kindness', 'wisdom', 'seen')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cU7R8QOrSfu6","executionInfo":{"status":"ok","timestamp":1745422766240,"user_tz":-180,"elapsed":42,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"fa3aa0d5-c791-49c3-ca2c-8779bf0720a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["seen\n"]}]},{"cell_type":"code","source":["print(wv.doesnt_match(('earth', 'sun', 'space')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LT2_rTKKSSx4","executionInfo":{"status":"ok","timestamp":1745422777177,"user_tz":-180,"elapsed":4,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"33695288-dcfc-42ec-da04-1426977046b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["space\n"]}]},{"cell_type":"markdown","metadata":{"id":"FwgLBaTM23ue"},"source":["Геометрические операции.\n","\n","Вектор 'France' минус вектор 'Paris' плюс вектор 'Moscow'. Получится какой-то вектор. Его может не быть в словаре, найдем ближайшие из словаря к нему, метод `.similar_by_vector()`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1745422839042,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"NCYoxEHB23ue","outputId":"c3d5350b-5f15-46f7-e8cd-1f7d3745568f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('russia', 0.7244411110877991),\n"," ('finland', 0.7233346700668335),\n"," ('eritrea', 0.7111433148384094),\n"," ('libya', 0.7041143774986267),\n"," ('lithuania', 0.7000227570533752),\n"," ('afghanistan', 0.6825510263442993),\n"," ('kosovo', 0.6822386980056763),\n"," ('ethiopia', 0.6818124651908875),\n"," ('yugoslavia', 0.679112434387207),\n"," ('moldova', 0.6747440099716187)]"]},"metadata":{},"execution_count":45}],"source":["Russia=wv['france']-wv['paris']+wv['moscow']\n","wv.similar_by_vector(Russia)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1745422999140,"user":{"displayName":"alx ikona","userId":"11385622684299513872"},"user_tz":-180},"id":"7GifuP9hR1-_","outputId":"daf2a185-83c9-42b4-a160-98453b663998"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('transitive', 0.5898538827896118),\n"," ('reactive', 0.5661169290542603),\n"," ('confusing', 0.5546857118606567),\n"," ('conversely', 0.5462662577629089),\n"," ('passive', 0.540286660194397),\n"," ('lateral', 0.5354853868484497),\n"," ('sticky', 0.5318681597709656),\n"," ('odor', 0.5311582088470459),\n"," ('slippery', 0.5310492515563965),\n"," ('intuitively', 0.5264121890068054)]"]},"metadata":{},"execution_count":48}],"source":["q=wv['drunk']-wv['was']+wv['is']\n","wv.similar_by_vector(q)"]},{"cell_type":"code","source":["q=wv['education']-wv['teacher']+wv['tutorial'] # = финансирование и здравоохранение))\n","wv.similar_by_vector(q)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lpn6qdFIT0zp","executionInfo":{"status":"ok","timestamp":1745423159408,"user_tz":-180,"elapsed":17,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"7f397c9c-0eef-4c2b-a1e1-e98a8bc60204"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('education', 0.7109248638153076),\n"," ('funding', 0.6287181377410889),\n"," ('healthcare', 0.6210781335830688),\n"," ('banking', 0.6127842664718628),\n"," ('infrastructure', 0.6112090349197388),\n"," ('pricing', 0.6110905408859253),\n"," ('transportation', 0.6021290421485901),\n"," ('resource', 0.597953736782074),\n"," ('accounting', 0.5979336500167847),\n"," ('maintenance', 0.5913182497024536)]"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["Обычно слова, учавствующие в исходном примере, не учитываются в результатх!"],"metadata":{"id":"hTPynMISVFjZ"}},{"cell_type":"markdown","metadata":{"id":"4QS6pGzd23ue"},"source":["А на русском языке??\n","\n","Такие модели тоже есть, но они гораздо слабее, мало слов, мало текстов.\n","Загрузим модель word2vec-ruscorpora-300 . Всего-то 200 тысяч слов."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOWgBWZa23ug"},"outputs":[],"source":["wv_rus = api.load('word2vec-ruscorpora-300')"]},{"cell_type":"markdown","metadata":{"id":"XTcErjx923ug"},"source":["Здесь слова имеют приставки, показывающие их часть речи."]},{"cell_type":"markdown","metadata":{"id":"175L8SiI23ug"},"source":["Что получится для король - мужчина + женщина ?\n","По идее королева. Но получится король. Но и \"правильный\" ответ тоже недалеко, второй по счету.   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBtwTl2n23ug","executionInfo":{"status":"ok","timestamp":1745423180912,"user_tz":-180,"elapsed":302,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"38eb1dad-792c-46e0-82c1-e269a86498f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('король_NOUN', 0.8805387616157532),\n"," ('королева_NOUN', 0.7313904762268066),\n"," ('герцог_NOUN', 0.6502388715744019),\n"," ('принцесса_NOUN', 0.6266285181045532),\n"," ('герцогиня_NOUN', 0.6240381598472595),\n"," ('королевство_NOUN', 0.6094207167625427),\n"," ('зюдерманландский_ADJ', 0.6084389686584473),\n"," ('дурлахский_ADJ', 0.6081665754318237),\n"," ('ульрик::элеонора_NOUN', 0.6073107719421387),\n"," ('максимилианов_NOUN', 0.6057003736495972)]"]},"metadata":{},"execution_count":55}],"source":["queen= wv_rus['король_NOUN'] - wv_rus['мужчина_NOUN'] + wv_rus['женщина_NOUN']\n","\n","wv_rus.similar_by_vector(queen)"]},{"cell_type":"markdown","metadata":{"id":"EuD6ipd223uh"},"source":["# Задания\n","Успешность геометрических операций с векторами слов сильно зависит и от вида модели и от текстов, на которых она обучалась. Не все понятные человеку аналогии слов, получаются и в компьютере. В качестве упражнения попробуйте найти примеры логичных и нелогичных аналогий."]},{"cell_type":"code","source":["vector_rus= wv_rus['сухость_NOUN'] - wv_rus['солнце_NOUN'] + wv_rus['дождь_NOUN'] # загадано слово сырость\n","\n","wv_rus.similar_by_vector(vector_rus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WzUm1uFhxP1","executionInfo":{"status":"ok","timestamp":1745426555038,"user_tz":-180,"elapsed":47,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"7e3c9a8b-dd70-4f5b-8828-c63255a56c25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('сухость_NOUN', 0.7094947695732117),\n"," ('дождь_NOUN', 0.5075872540473938),\n"," ('сырость_NOUN', 0.4462027847766876),\n"," ('слякоть_NOUN', 0.44024986028671265),\n"," ('дождик_NOUN', 0.43771594762802124),\n"," ('проливной::дождь_NOUN', 0.4273136854171753),\n"," ('моросить_VERB', 0.41848400235176086),\n"," ('простуда_NOUN', 0.40747982263565063),\n"," ('ливень_NOUN', 0.4037167727947235),\n"," ('мокрота_NOUN', 0.39950791001319885)]"]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["Пример взаимосвязи, понятной как человеку, так и модели."],"metadata":{"id":"AYPCzd5xcnb6"}},{"cell_type":"code","source":["vector_rus= wv_rus['металл_NOUN'] - wv_rus['кузов_NOUN'] + wv_rus['избушка_NOUN'] # загадано слово дерево\n","\n","wv_rus.similar_by_vector(vector_rus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCgbCssOgn3d","executionInfo":{"status":"ok","timestamp":1745426701399,"user_tz":-180,"elapsed":48,"user":{"displayName":"alx ikona","userId":"11385622684299513872"}},"outputId":"c7c52a5a-ea53-4b78-d207-995d5bc96b39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('избушка_NOUN', 0.5858855843544006),\n"," ('металл_NOUN', 0.5510308742523193),\n"," ('олово_NOUN', 0.44988763332366943),\n"," ('ниобиевый_ADJ', 0.4117943048477173),\n"," ('апатитовый::руда_NOUN', 0.411454439163208),\n"," ('медь_NOUN', 0.41075730323791504),\n"," ('курий::ножка_NOUN', 0.4064829349517822),\n"," ('мышьяк::сурьма_NOUN', 0.4055791199207306),\n"," ('никель::кобальт_NOUN', 0.4040985703468323),\n"," ('криолит_NOUN', 0.40299975872039795)]"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["Мы хотим найти слово, которое относится к слову \"избушка\" так же, как слово \"металл\" относится к слово \"кузов\".\n","\n","Это можно записать как уравнение:\n","кузов : металл = избушка : ?\n","\n","Или в векторной форме:\n","vector_rus = металл - кузов + избушка\n","Модель ищет в своем словаре слова, чьи векторы ближе всего к полученному vector_rus (близость измеряется косинусным сходством)."],"metadata":{"id":"qw9zNeQpejXV"}},{"cell_type":"markdown","source":["Такая взаимосвязь вполне очевидна для человека, но не очевидна для модели (из-за сложной логики или редкости сочетаний). Модель больше цепляется за используемые в примере термины, поэтому выдает в качестве ответов \"различные металлы\". Наверное, это и к лучшему, иначе бы наша модель во всем видела \"потайные\" смыслы."],"metadata":{"id":"1o3iuWpycyKL"}},{"cell_type":"markdown","metadata":{"id":"il0jKMxH23uh"},"source":["# Заключение\n","Сегодня существует множество моделей для векторных представлений слов на разных языках. По похожему принципу строятся и векторные представления предложений и даже текстов целиком. Мы еще познакомимся с некоторыми примерами в этой области."]},{"cell_type":"markdown","metadata":{"id":"fHQmJaAJ23ui"},"source":["## Ссылки\n","\n","Использованы и адаптированы материалы:\n","* https://radimrehurek.com/gensim/index.html\n","* https://medium.com/sciforce/word-vectors-in-natural-language-processing-global-vectors-glove-51339db89639\n","* https://colab.research.google.com/github/mdda/deep-learning-workshop/blob/master/notebooks/5-RNN/3-Text-Corpus-and-Embeddings.ipynb#scrollTo=h-CQETk6HPmx\n","* https://radimrehurek.com/gensim/models/fasttext.html\n","* https://amitness.com/2020/06/fasttext-embeddings/\n","* http://vectors.nlpl.eu/explore/embeddings\n","\n","Рекомендую посмотреть курсы:\n","* First Step in NLP https://stepik.org/course/129443/syllabus\n","* Second Step in NLP https://stepik.org/course/133963/syllabus"]}],"metadata":{"colab":{"provenance":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}